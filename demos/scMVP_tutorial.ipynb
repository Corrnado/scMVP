{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Introduction to single-cell multi-view profiler (scMVP)\n",
    "In this introductory tutorial, we present the different tasks of a scMVP workflow\n",
    "1. Loading the multi-omics data\n",
    "2. Training the multi-view model\n",
    "3. Retrieving the common latent space and imputed multi-omics values\n",
    "4. Perform cell clustering and differential expression \n",
    "5. Visualize the common latent space and clustering with umap\n",
    "6. The differential gene cluster identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-09-21 18:35:12,747] INFO - scMVP._settings | Added StreamHandler with custom formatter to 'scMVP' logger.\n",
      "/home/fusl/miniconda2/envs/scMVP/lib/python3.7/site-packages/scikit_learn-0.22.2-py3.7-linux-x86_64.egg/sklearn/utils/linear_assignment_.py:22: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scMVP.dataset import scienceDataset, SciCarDemo\n",
    "from scMVP.models import VAE\n",
    "from scMVP.inference import UnsupervisedTrainer\n",
    "from scMVP.inference import MultiPosterior, MultiTrainer\n",
    "import torch\n",
    "from scMVP.models.multi_vae import Multi_VAE\n",
    "\n",
    "## Visualizing the latent space with scanpy\n",
    "import scanpy as sc\n",
    "import anndata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Loading data\n",
    "\n",
    " Loading the sci-CAR cell line dataset described in Junyue Cao et al. (2018).\n",
    "\n",
    "* Junyue Cao, et al. \"Joint profiling of chromatin accessibility and gene expression in thousands of single cells.\" Science 361.6409 (2018): 1380-1385. \n",
    "\n",
    "Data url: https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE117089&format=file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-09-21 21:16:21,263] INFO - scMVP.dataset.scienceDataset | Preprocessing dataset\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset/sci_car/GSM3271040_RNA_sciCAR_A549_gene.count.mtx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-577eae4d8315>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtest_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"dataset/sci_car/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscienceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"CellLineMixture\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeasurement_names_column\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda2/envs/scMVP/lib/python3.7/site-packages/scMVP-0.0.1-py3.7.egg/scMVP/dataset/scienceDataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset_name, save_path, type, dense, measurement_names_column, remove_extracted_data, delayed_populating, datatype, is_binary)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdelayed_populating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpopulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/scMVP/lib/python3.7/site-packages/scMVP-0.0.1-py3.7.egg/scMVP/dataset/scienceDataset.py\u001b[0m in \u001b[0;36mpopulate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_path_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_path_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tarfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Extracting tar file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                     \u001b[0mtar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r:gz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/scMVP/lib/python3.7/tarfile.py\u001b[0m in \u001b[0;36mis_tarfile\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m   2440\u001b[0m     \"\"\"\n\u001b[1;32m   2441\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2442\u001b[0;31m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2443\u001b[0m         \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2444\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/scMVP/lib/python3.7/tarfile.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(cls, name, mode, fileobj, bufsize, **kwargs)\u001b[0m\n\u001b[1;32m   1573\u001b[0m                     \u001b[0msaved_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1574\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1575\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1576\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mReadError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompressionError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1577\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/scMVP/lib/python3.7/tarfile.py\u001b[0m in \u001b[0;36mgzopen\u001b[0;34m(cls, name, mode, fileobj, compresslevel, **kwargs)\u001b[0m\n\u001b[1;32m   1637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1640\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/scMVP/lib/python3.7/gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset/sci_car/GSM3271040_RNA_sciCAR_A549_gene.count.mtx'"
     ]
    }
   ],
   "source": [
    "def allow_mmvae_for_test():\n",
    "    print(\"Testing the basic tutorial scMVP\")\n",
    "\n",
    "test_mode = False\n",
    "save_path = \"data/\"\n",
    "n_epochs_all = None\n",
    "show_plot = True\n",
    "\n",
    "if not test_mode:\n",
    "    save_path = \"dataset/\"\n",
    "dataset = scienceDataset(dataset_name=\"CellLineMixture\", save_path=save_path, measurement_names_column=1, is_binary = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data filtering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def filter_dataset(dataset):\n",
    "    high_count_genes = (dataset.X > 0).sum(axis=0).ravel() > 0.01 * dataset.X.shape[0]\n",
    "    dataset.update_genes(high_count_genes)\n",
    "    dataset.subsample_genes(new_n_genes=10000)\n",
    "    \n",
    "    high_gene_count_cells = (dataset.X > 0).sum(axis=1).ravel() > 50\n",
    "    #high_atac_cells = dataset.atac_expression.sum(axis=1) >= np.percentile(dataset.atac_expression.sum(axis=1), 10)\n",
    "    high_atac_cells = dataset.atac_expression.sum(axis=1) >= np.percentile(dataset.atac_expression.sum(axis=1), 1)\n",
    "    inds_to_keep = np.logical_and(high_gene_count_cells, high_atac_cells)\n",
    "    dataset.update_cells(inds_to_keep)\n",
    "    return dataset, inds_to_keep\n",
    "\n",
    "if test_mode is False:\n",
    "    dataset, inds_to_keep = filter_dataset(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __n_epochs__: Maximum number of epochs to train the model. If the likelihood change is small than a set threshold training will stop automatically. \n",
    "* __lr__: learning rate. Set to 0.001 here. \n",
    "* __use_batches__: If the value of true than batch information is used in the training. Here it is set to false because the cortex data only contains one batch. \n",
    "* __use_cuda__: Set to true to use CUDA (GPU required) \n",
    "* __n_centroids__: Set the number of cell types\n",
    "* __n_alfa__: Set the weight of KL loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_epochs = 50 if n_epochs_all is None else n_epochs_all\n",
    "lr = 1e-3\n",
    "use_batches = False\n",
    "use_cuda = True\n",
    "n_centroids = 5\n",
    "n_alfa = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Pre-training\n",
    "runing pre-train vae to initialize the Gaussian Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pre_vae = VAE(dataset.nb_genes, n_batch=256)\n",
    "pre_trainer = UnsupervisedTrainer(\n",
    "    pre_vae,\n",
    "    dataset,\n",
    "    train_size=0.75,\n",
    "    use_cuda=use_cuda,\n",
    "    frequency=5\n",
    ")\n",
    "is_test_pragram = False\n",
    "if is_test_pragram:\n",
    "    pre_trainer.train(n_epochs=n_epochs, lr=lr)\n",
    "    torch.save(pre_trainer.model.state_dict(), '%s/pre_trainer6.pkl' % save_path)\n",
    "\n",
    "if os.path.isfile('%s/pre_trainer6.pkl' % save_path):\n",
    "    pre_trainer.model.load_state_dict(torch.load('%s/pre_trainer6.pkl' % save_path))\n",
    "    pre_trainer.model.eval()\n",
    "else:\n",
    "    #pre_trainer.model.init_gmm_params(dataset)\n",
    "    pre_trainer.train(n_epochs=n_epochs, lr=lr)\n",
    "    torch.save(pre_trainer.model.state_dict(), '%s/pre_trainer6.pkl' % save_path)\n",
    "\n",
    "# pretrainer_posterior:\n",
    "full = pre_trainer.create_posterior(pre_trainer.model, dataset, indices=np.arange(len(dataset)))\n",
    "latent, batch_indices, labels = full.sequential().get_latent()\n",
    "batch_indices = batch_indices.ravel()\n",
    "imputed_values = full.sequential().imputation()\n",
    "\n",
    "sample_latents = torch.tensor([])\n",
    "samples = torch.tensor([])\n",
    "sample_labels = torch.tensor([])\n",
    "for tensors_list in range(int(len(imputed_values)/256)+1):\n",
    "    if tensors_list == range(int(len(imputed_values)/256)):\n",
    "        x = torch.zeros((256,len(imputed_values[0])))\n",
    "        x[0:len(x)-256*tensors_list,:] = torch.tensor(imputed_values[tensors_list * 256:len(imputed_values), :])\n",
    "        y = torch.zeros((256))\n",
    "        y[0:len(x)-256*tensors_list,:]  = torch.tensor(dataset.labels[tensors_list * 256:len(imputed_values)].astype(int))\n",
    "        temp_samples = pre_trainer.model.get_latents(x,y)\n",
    "        for temp_sample in temp_samples:\n",
    "            sample_latents = torch.cat((sample_latents, temp_sample[0:len(x)-256*tensors_list,:].float()))\n",
    "    temp_samples = pre_trainer.model.get_latents(\n",
    "        x=torch.tensor(imputed_values[tensors_list * 256:(1 + tensors_list) * 256, :]),\n",
    "        y=torch.tensor(dataset.labels[tensors_list * 256:(1 + tensors_list) * 256].astype(int)))\n",
    "    for temp_sample in temp_samples:\n",
    "        sample_latents = torch.cat((sample_latents, temp_sample.float()))\n",
    "        \n",
    "# visulization\n",
    "prior_adata = anndata.AnnData(X=dataset.X)\n",
    "prior_adata.obsm[\"X_multi_vi\"] = sample_latents.detach().numpy()\n",
    "prior_adata.obs['cell_type'] = torch.tensor(dataset.labels[0:len(sample_latents)].astype(int))\n",
    "sc.pp.neighbors(prior_adata, use_rep=\"X_multi_vi\", n_neighbors=15)\n",
    "sc.tl.umap(prior_adata, min_dist=0.1)\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "sc.pl.umap(prior_adata, color=[\"cell_type\"], ax=ax, show=show_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training scMVP\n",
    "We now create the scMVP model and the trainer object.\n",
    "\n",
    "If a pre-trained model already exist in the save_path then load the same model rather than re-training it. This is particularly useful for large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "multi_vae = Multi_VAE(dataset.nb_genes, len(dataset.atac_names), n_batch=256, n_centroids=n_centroids, n_alfa = n_alfa, mode=\"mm-vae\") # should provide ATAC num, alfa, mode and loss type\n",
    "trainer = MultiTrainer(\n",
    "    multi_vae,\n",
    "    dataset,\n",
    "    train_size=0.75,\n",
    "    use_cuda=use_cuda,\n",
    "    frequency=5,\n",
    ")\n",
    "\n",
    "clust_index_gmm = trainer.model.init_gmm_params(sample_latents.detach().numpy())\n",
    "\n",
    "is_test_pragram = False\n",
    "if is_test_pragram:\n",
    "    trainer.train(n_epochs=n_epochs, lr=lr)\n",
    "    torch.save(trainer.model.state_dict(), '%s/multi_vae_21.pkl' % save_path)\n",
    "if os.path.isfile('%s/multi_vae_21.pkl' % save_path):\n",
    "    trainer.model.load_state_dict(torch.load('%s/multi_vae_21.pkl' % save_path))\n",
    "    trainer.model.eval()\n",
    "else:\n",
    "    trainer.train(n_epochs=n_epochs, lr=lr)\n",
    "    torch.save(trainer.model.state_dict(), '%s/multi_vae_21.pkl' % save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Plotting the likelihood change across the n epochs of training: blue for training error and orange for testing error.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## If you train your own model, you can plot the elbo value during training.\n",
    "## If your load pre-trained model, the plot would be empty.\n",
    "\n",
    "elbo_train_set = trainer.history[\"elbo_train_set\"]\n",
    "elbo_test_set = trainer.history[\"elbo_test_set\"]\n",
    "x = np.linspace(0, 500, (len(elbo_train_set)))\n",
    "plt.plot(x, elbo_train_set)\n",
    "plt.plot(x, elbo_test_set)\n",
    "plt.ylim(1150, 1600)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Query the imputed values via the `imputation` method of the posterior object and get common latent embedding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "full = trainer.create_posterior(trainer.model, dataset, indices=np.arange(len(dataset)),type_class=MultiPosterior)\n",
    "imputed_values = full.sequential().imputation()\n",
    "sample_latents = torch.tensor([])\n",
    "sample_labels = torch.tensor([])\n",
    "rna_imputation = imputed_values[0]\n",
    "atac_imputation = imputed_values[3]\n",
    "temp_label = []\n",
    "sample_latents = torch.tensor([])\n",
    "samples = torch.tensor([])\n",
    "sample_labels = torch.tensor([])\n",
    "if len(imputed_values) >= 3:\n",
    "    temp_label = imputed_values[2]\n",
    "for tensors_list in range(int(len(imputed_values[0])/256)+1):\n",
    "    if temp_label.any():\n",
    "        temp_samples = trainer.model.get_latents(x_rna=torch.tensor(rna_imputation[tensors_list*256:(1+tensors_list)*256,:]),\n",
    "                                                x_atac=torch.tensor(atac_imputation[tensors_list*256:(1+tensors_list)*256,:]),\n",
    "                                                y=torch.tensor(temp_label[tensors_list*256:(1+tensors_list)*256])) \n",
    "    else:\n",
    "        temp_samples = trainer.model.get_latents(x_rna=torch.tensor(rna_imputation[tensors_list*256:(1+tensors_list)*256,:]),\n",
    "                                                x_atac=torch.tensor(atac_imputation[tensors_list*256:(1+tensors_list)*256,:]),\n",
    "                                                y=torch.tensor(np.zeros(256))) \n",
    "    for temp_sample in temp_samples:\n",
    "        #sample_latents = torch.cat((sample_latents, temp_sample[2].float()))\n",
    "        sample_latents = torch.cat((sample_latents, temp_sample[0][0].float()))\n",
    "        sample_labels = torch.cat((sample_labels, torch.tensor(temp_label[tensors_list*256:(1+tensors_list)*256]).float()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Cell clustering\n",
    "Perform cell clustering and merging the rare clusters which less than 10 cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clust_index_gmm = trainer.model.init_gmm_params(sample_latents.detach().numpy())\n",
    "gmm_clus_index = clust_index_gmm.reshape(-1,1)\n",
    "for i in range(len(np.unique(gmm_clus_index))):\n",
    "    if len(gmm_clus_index[gmm_clus_index == i]) <= 10:\n",
    "        for j in range(len(np.unique(gmm_clus_index))):\n",
    "            if len(gmm_clus_index[gmm_clus_index == j]) > 100:\n",
    "                gmm_clus_index[gmm_clus_index == i] = j\n",
    "                break\n",
    "unique_gmm_clus_index = np.unique(gmm_clus_index)\n",
    "for i in range(len(unique_gmm_clus_index)):\n",
    "    gmm_clus_index[gmm_clus_index == unique_gmm_clus_index[i]] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing common latent embedding and cell clustering by scMVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "posterior_adata = anndata.AnnData(X=rna_imputation)\n",
    "posterior_adata.obsm[\"X_multi_vi\"] = sample_latents.detach().numpy()\n",
    "posterior_adata.obs['cell_type'] = torch.tensor(clust_index_gmm.reshape(-1,1))\n",
    "sc.pp.neighbors(posterior_adata, use_rep=\"X_multi_vi\", n_neighbors=15)\n",
    "sc.tl.umap(posterior_adata, min_dist=0.1)\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "sc.pl.umap(posterior_adata, color=[\"cell_type\"], ax=ax, show=show_plot)\n",
    "# imputation labels\n",
    "posterior_adata.obs['cell_type'] = torch.tensor(sample_labels.reshape(-1,1))\n",
    "sc.pp.neighbors(posterior_adata, use_rep=\"X_multi_vi\", n_neighbors=15)\n",
    "sc.tl.umap(posterior_adata, min_dist=0.1)\n",
    "#matplotlib.use('TkAgg')\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "sc.pl.umap(posterior_adata, color=[\"cell_type\"], ax=ax, show=show_plot)\n",
    "sc.tl.louvain(posterior_adata)\n",
    "sc.pl.umap(posterior_adata, color=['louvain'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## differential gene and peak analysis\n",
    "Identification differential genes and peaks in each cell cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "posterior_adata.obs['louvain'] = torch.tensor(gmm_clus_index.reshape(-1,1))\n",
    "sc.tl.rank_genes_groups(posterior_adata, 'louvain')\n",
    "sc.pl.rank_genes_groups(posterior_adata, n_genes=10, sharey=False)\n",
    "diff_top_gene_set = posterior_adata.uns['rank_genes_groups']\n",
    "diff_top_gene_set = (diff_top_gene_set['names'])\n",
    "diff_top_gene_pvalue_set = posterior_adata.uns['rank_genes_groups']\n",
    "diff_top_gene_pvalue_set = (diff_top_gene_pvalue_set['pvals_adj'])\n",
    "diff_top_gene_foldchange_set = posterior_adata.uns['rank_genes_groups']\n",
    "diff_top_gene_foldchange_set = (diff_top_gene_foldchange_set['logfoldchanges'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atac_posterior_adata = anndata.AnnData(X=atac_imputation)\n",
    "atac_posterior_adata.obs['louvain'] = posterior_adata.obs['louvain']\n",
    "sc.tl.rank_genes_groups(atac_posterior_adata, 'louvain',n_genes=1000)\n",
    "sc.pl.rank_genes_groups(atac_posterior_adata, n_genes=10, sharey=False)\n",
    "atac_diff_top_gene_set = atac_posterior_adata.uns['rank_genes_groups']\n",
    "atac_diff_top_gene_set = (atac_diff_top_gene_set['names'])\n",
    "atac_diff_top_gene_pvalue_set = atac_posterior_adata.uns['rank_genes_groups']\n",
    "atac_diff_top_gene_pvalue_set = (atac_diff_top_gene_pvalue_set['pvals_adj'])\n",
    "atac_diff_top_gene_foldchange_set = atac_posterior_adata.uns['rank_genes_groups']\n",
    "atac_diff_top_gene_foldchange_set = (atac_diff_top_gene_foldchange_set['logfoldchanges'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
